{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercice - Mauvais entraînement Keras\n",
        "Ce notebook illustre un entraînement **sans** séparation en train/val/test, sans gestion du déséquilibre de classes et **sans** surveillance de l'overfitting via l'early stopping."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "print(\"Using TensorFlow version:\", tf.__version__)\n",
        "\n",
        "# Pour reproduire un comportement stable (optionnel)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Chargement du dataset sans split\n",
        "Ici, **on ne fait aucun split** : on utilise exactement les mêmes données pour l'entraînement et l'évaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Chemin vers le dossier qui contient les deux sous-dossiers : 'good' et 'defect'\n",
        "DATA_DIR = \"path_to_your_mvtec_dataset\"  # À adapter\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "# Charger toutes les images d'un seul tenant\n",
        "dataset = image_dataset_from_directory(\n",
        "    DATA_DIR,\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',  # Pour un problème multi-classes, ici on suppose 2 classes (good, defect)\n",
        "    batch_size=BATCH_SIZE,\n",
        "    image_size=IMG_SIZE,\n",
        "    shuffle=True  # Mélange les données\n",
        ")\n",
        "\n",
        "# Afficher les classes détectées\n",
        "class_names = dataset.class_names\n",
        "print(\"Classes détectées :\", class_names)\n",
        "\n",
        "# Optionnel : Normalisation et mise en cache\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "def preprocess(image, label):\n",
        "    image = tf.cast(image, tf.float32) / 255.0  # Normalisation simple\n",
        "    return image, label\n",
        "\n",
        "dataset = dataset.map(preprocess).cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Définition d'un modèle simple\n",
        "On définit un modèle CNN très basique."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "num_classes = len(class_names)\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(16, (3, 3), activation='relu', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Entraînement du modèle \n",
        "Ici, **aucun** validation_split, **aucun** EarlyStopping, et **aucune** gestion du déséquilibre de classes (pas de `class_weight`).\n",
        "\n",
        "On entraîne et on \"évalue\" sur le **même** dataset, ce qui est une très mauvaise pratique, provoquant potentiellement un fort surapprentissage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "EPOCHS = 10  # Nombre d'époques d'entraînement\n",
        "\n",
        "history = model.fit(\n",
        "    dataset,                 # Entraînement ET test sur le même dataset\n",
        "    epochs=EPOCHS,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Évaluation sur le même dataset\n",
        "On évalue le modèle sur **le même** jeu de données utilisé à l’entraînement. Ceci donnera généralement une performance artificiellement gonflée."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "loss, accuracy = model.evaluate(dataset, verbose=0)\n",
        "print(f\"Loss sur le dataset complet : {loss:.4f}\")\n",
        "print(f\"Accuracy sur le dataset complet : {accuracy:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Conclusion\n",
        "Ce notebook est un **exemple à ne pas reproduire** dans un projet réel. \n",
        "\n",
        "- **Pas de split train/val/test** : on doit toujours avoir un jeu de validation ou de test distinct pour évaluer la capacité de généralisation.\n",
        "- **Pas de gestion du déséquilibre** : si la classe 'good' est sur-représentée par rapport à 'defect', le modèle aura tendance à ne prédire que la classe majoritaire.\n",
        "- **Pas de mécanisme d'early stopping** : risque d'overfitting si on entraîne trop longtemps.\n",
        "\n",
        "Ce script répond uniquement à la demande d'illuster un *mauvais* setup d'entraînement."
      ]
    }
  ],
  "metadata": {
    "name": "bad_training",
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "bad_training.ipynb"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
