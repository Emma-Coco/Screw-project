{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "kbuJwbDWlH6V",
      "metadata": {
        "id": "kbuJwbDWlH6V"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using TensorFlow version: 2.18.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"Using TensorFlow version:\", tf.__version__)\n",
        "\n",
        "# Pour reproduire un comportement stable (optionnel)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BL4ryDxBlH6X",
      "metadata": {
        "id": "BL4ryDxBlH6X"
      },
      "source": [
        "## 1. Chargement du dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oPdyTXM1lH6X",
      "metadata": {
        "id": "oPdyTXM1lH6X"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1152 files belonging to 2 classes.\n",
            "Classes détectées : ['bad', 'good']\n"
          ]
        }
      ],
      "source": [
        "# # Chemin vers le dossier qui contient les deux sous-dossiers : 'good' et 'defect'\n",
        "# DATA_DIR = \"screw_dataset\"  # À adapter\n",
        "\n",
        "# BATCH_SIZE = 32\n",
        "# IMG_SIZE = (224, 224)\n",
        "\n",
        "# # Charger toutes les images d'un seul tenant\n",
        "# dataset = image_dataset_from_directory(\n",
        "#     DATA_DIR,\n",
        "#     labels='inferred',\n",
        "#     label_mode='categorical',  # Pour un problème multi-classes, ici on suppose 2 classes (good, defect)\n",
        "#     batch_size=BATCH_SIZE,\n",
        "#     image_size=IMG_SIZE,\n",
        "#     shuffle=True  # Mélange les données\n",
        "# )\n",
        "\n",
        "# # Afficher les classes détectées\n",
        "# class_names = dataset.class_names\n",
        "# print(\"Classes détectées :\", class_names)\n",
        "\n",
        "# # Optionnel : Normalisation et mise en cache\n",
        "# AUTOTUNE = tf.data.AUTOTUNE\n",
        "# def preprocess(image, label):\n",
        "#     image = tf.cast(image, tf.float32) / 255.0  # Normalisation simple\n",
        "#     return image, label\n",
        "\n",
        "# dataset = dataset.map(preprocess).cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2a3c4ac",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chargement des images depuis les dossiers...\n",
            "Found 1152 files belonging to 2 classes.\n",
            "Classes détectées : ['bad', 'good']\n",
            "Nombre total d'images: 1152\n",
            "\n",
            "=== DISTRIBUTION DES CLASSES DANS LES DONNÉES ORIGINALES ===\n",
            "Classe 'bad' (indice 0): 285 images (24.7%)\n",
            "Classe 'good' (indice 1): 867 images (75.3%)\n",
            "============================================================\n",
            "\n",
            "=== TABLEAU SHUFFLÉ (FORMAT SIMPLIFIÉ) ===\n",
            "[0] | classe=0 (bad) | one-hot=[1. 0.]\n",
            "[1] | classe=1 (good) | one-hot=[0. 1.]\n",
            "[2] | classe=1 (good) | one-hot=[0. 1.]\n",
            "[3] | classe=0 (bad) | one-hot=[1. 0.]\n",
            "[4] | classe=1 (good) | one-hot=[0. 1.]\n",
            "[5] | classe=0 (bad) | one-hot=[1. 0.]\n",
            "[6] | classe=1 (good) | one-hot=[0. 1.]\n",
            "[7] | classe=1 (good) | one-hot=[0. 1.]\n",
            "[8] | classe=1 (good) | one-hot=[0. 1.]\n",
            "[9] | classe=1 (good) | one-hot=[0. 1.]\n",
            "============================================================\n",
            "\n",
            "Division des données en ensembles d'entraînement, validation et test...\n",
            "Ensemble d'entraînement: 806 images\n",
            "Ensemble de validation: 173 images\n",
            "Ensemble de test: 173 images\n",
            "\n",
            "=== EXEMPLES DE L'ENSEMBLE D'ENTRAÎNEMENT (FORMAT SIMPLIFIÉ) ===\n",
            "[0] | classe=1 (good) | one-hot=[0. 1.]\n",
            "[1] | classe=0 (bad) | one-hot=[1. 0.]\n",
            "[2] | classe=1 (good) | one-hot=[0. 1.]\n",
            "[3] | classe=1 (good) | one-hot=[0. 1.]\n",
            "[4] | classe=1 (good) | one-hot=[0. 1.]\n",
            "[5] | classe=1 (good) | one-hot=[0. 1.]\n",
            "[6] | classe=1 (good) | one-hot=[0. 1.]\n",
            "[7] | classe=1 (good) | one-hot=[0. 1.]\n",
            "[8] | classe=1 (good) | one-hot=[0. 1.]\n",
            "[9] | classe=1 (good) | one-hot=[0. 1.]\n",
            "============================================================\n",
            "\n",
            "=== STATISTIQUES DES ENSEMBLES ===\n",
            "Distribution des classes dans chaque ensemble:\n",
            "Classe 'bad' (indice 0):\n",
            "  - Train: 199 images (24.7%)\n",
            "  - Validation: 43 images (24.9%)\n",
            "  - Test: 43 images (24.9%)\n",
            "Classe 'good' (indice 1):\n",
            "  - Train: 607 images (75.3%)\n",
            "  - Validation: 130 images (75.1%)\n",
            "  - Test: 130 images (75.1%)\n",
            "============================================================\n",
            "\n",
            "Les datasets sont prêts à être utilisés pour l'entraînement!\n"
          ]
        }
      ],
      "source": [
        "# Chemins et paramètres\n",
        "DATA_DIR = \"screw_dataset\"\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (224, 224)\n",
        "NUM_SAMPLES_TO_SHOW = 10  # Nombre d'exemples à afficher\n",
        "TRAIN_RATIO = 0.7\n",
        "VAL_RATIO = 0.15\n",
        "TEST_RATIO = 0.15\n",
        "\n",
        "print(\"Chargement des images depuis les dossiers...\")\n",
        "\n",
        "# Charger le dataset\n",
        "dataset = image_dataset_from_directory(\n",
        "    DATA_DIR,\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    image_size=IMG_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Afficher les classes détectées\n",
        "class_names = dataset.class_names\n",
        "print(\"Classes détectées :\", class_names)\n",
        "\n",
        "# Convertir le dataset en tableaux numpy\n",
        "all_images = []\n",
        "all_labels = []\n",
        "\n",
        "for images, labels in dataset:\n",
        "    all_images.append(images.numpy())\n",
        "    all_labels.append(labels.numpy())\n",
        "\n",
        "# Concaténer tous les batches\n",
        "X = np.concatenate(all_images, axis=0)\n",
        "y = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "# Normaliser les valeurs des pixels\n",
        "X = X / 255.0\n",
        "\n",
        "print(f\"Nombre total d'images: {X.shape[0]}\")\n",
        "\n",
        "# Distribution originale des classes\n",
        "class_counts = np.sum(y, axis=0)\n",
        "total_images = np.sum(class_counts)\n",
        "print(\"\\n=== DISTRIBUTION DES CLASSES DANS LES DONNÉES ORIGINALES ===\")\n",
        "for i, class_name in enumerate(class_names):\n",
        "    count = int(class_counts[i])\n",
        "    percentage = (count / total_images) * 100\n",
        "    print(f\"Classe '{class_name}' (indice {i}): {count} images ({percentage:.1f}%)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Créer des indices pour shuffle et garder la correspondance image/label\n",
        "indices = np.arange(X.shape[0])\n",
        "np.random.seed(42)  # Pour la reproductibilité\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# Mélanger les données\n",
        "X_shuffled = X[indices]\n",
        "y_shuffled = y[indices]\n",
        "\n",
        "# Afficher les premières lignes du tableau shufflé dans le format simplifié\n",
        "print(\"\\n=== TABLEAU SHUFFLÉ (FORMAT SIMPLIFIÉ) ===\")\n",
        "for i in range(NUM_SAMPLES_TO_SHOW):\n",
        "    label_index = np.argmax(y_shuffled[i])\n",
        "    label_name = class_names[label_index]\n",
        "    print(f\"[{i}] | classe={label_index} ({label_name}) | one-hot={y_shuffled[i]}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Division en ensembles train, validation et test\n",
        "print(\"\\nDivision des données en ensembles d'entraînement, validation et test...\")\n",
        "\n",
        "# Diviser en train et temp (validation + test)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X_shuffled, \n",
        "    y_shuffled,\n",
        "    train_size=TRAIN_RATIO,\n",
        "    random_state=42,\n",
        "    stratify=np.argmax(y_shuffled, axis=1)  # Assurer l'équilibre des classes\n",
        ")\n",
        "\n",
        "# Diviser temp en validation et test\n",
        "val_test_ratio = VAL_RATIO / (VAL_RATIO + TEST_RATIO)\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, \n",
        "    y_temp,\n",
        "    train_size=val_test_ratio,\n",
        "    random_state=42,\n",
        "    stratify=np.argmax(y_temp, axis=1)  # Assurer l'équilibre des classes\n",
        ")\n",
        "\n",
        "print(f\"Ensemble d'entraînement: {X_train.shape[0]} images\")\n",
        "print(f\"Ensemble de validation: {X_val.shape[0]} images\")\n",
        "print(f\"Ensemble de test: {X_test.shape[0]} images\")\n",
        "\n",
        "# Afficher quelques exemples de l'ensemble d'entraînement\n",
        "print(\"\\n=== EXEMPLES DE L'ENSEMBLE D'ENTRAÎNEMENT (FORMAT SIMPLIFIÉ) ===\")\n",
        "for i in range(NUM_SAMPLES_TO_SHOW):\n",
        "    label_index = np.argmax(y_train[i])\n",
        "    label_name = class_names[label_index]\n",
        "    print(f\"[{i}] | classe={label_index} ({label_name}) | one-hot={y_train[i]}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Créer les datasets TensorFlow\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "\n",
        "# Configurer les datasets pour l'entraînement\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_dataset = train_dataset.shuffle(buffer_size=X_train.shape[0]).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "\n",
        "# Vérifier la distribution des classes dans chaque ensemble\n",
        "train_class_counts = np.sum(y_train, axis=0)\n",
        "val_class_counts = np.sum(y_val, axis=0)\n",
        "test_class_counts = np.sum(y_test, axis=0)\n",
        "\n",
        "print(\"\\n=== STATISTIQUES DES ENSEMBLES ===\")\n",
        "print(\"Distribution des classes dans chaque ensemble:\")\n",
        "for i, class_name in enumerate(class_names):\n",
        "    print(f\"Classe '{class_name}' (indice {i}):\")\n",
        "    print(f\"  - Train: {int(train_class_counts[i])} images ({train_class_counts[i]/np.sum(train_class_counts)*100:.1f}%)\")\n",
        "    print(f\"  - Validation: {int(val_class_counts[i])} images ({val_class_counts[i]/np.sum(val_class_counts)*100:.1f}%)\")\n",
        "    print(f\"  - Test: {int(test_class_counts[i])} images ({test_class_counts[i]/np.sum(test_class_counts)*100:.1f}%)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nLes datasets sont prêts à être utilisés pour l'entraînement!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2NRj6R2GlH6Y",
      "metadata": {
        "id": "2NRj6R2GlH6Y"
      },
      "source": [
        "## 2. Définition d'un modèle simple\n",
        "On définit un modèle CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0Em3Ej3PlH6Y",
      "metadata": {
        "id": "0Em3Ej3PlH6Y"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/emmacoco/Library/Python/3.9/lib/python/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93312</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,972,032</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m448\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m4,640\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93312\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │     \u001b[38;5;34m5,972,032\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m130\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,977,250</span> (22.80 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,977,250\u001b[0m (22.80 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,977,250</span> (22.80 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,977,250\u001b[0m (22.80 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "num_classes = len(class_names)\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(16, (3, 3), activation='relu', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='mse',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PnYnBDv0lH6Z",
      "metadata": {
        "id": "PnYnBDv0lH6Z"
      },
      "source": [
        "## 3. Entraînement du modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "V4q_eeIZlH6Z",
      "metadata": {
        "id": "V4q_eeIZlH6Z"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 1000  # Nombre d'époques d'entraînement\n",
        "\n",
        "history = model.fit(\n",
        "    dataset,                 # Entraînement ET test sur le même dataset\n",
        "    epochs=EPOCHS,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IquuiFNIlH6a",
      "metadata": {
        "id": "IquuiFNIlH6a"
      },
      "source": [
        "## 4. Évaluation sur le même dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EFp7dBImlH6a",
      "metadata": {
        "id": "EFp7dBImlH6a"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(dataset, verbose=0)\n",
        "print(f\"Loss sur le dataset complet : {loss:.4f}\")\n",
        "print(f\"Accuracy sur le dataset complet : {accuracy:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "name": "bad_training"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
