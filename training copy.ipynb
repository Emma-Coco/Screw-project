{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "kbuJwbDWlH6V",
      "metadata": {
        "id": "kbuJwbDWlH6V"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using TensorFlow version: 2.18.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"Using TensorFlow version:\", tf.__version__)\n",
        "\n",
        "# Pour reproduire un comportement stable (optionnel)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BL4ryDxBlH6X",
      "metadata": {
        "id": "BL4ryDxBlH6X"
      },
      "source": [
        "## 1. Chargement du dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oPdyTXM1lH6X",
      "metadata": {
        "id": "oPdyTXM1lH6X"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1152 files belonging to 2 classes.\n",
            "Classes détectées : ['bad', 'good']\n"
          ]
        }
      ],
      "source": [
        "# # Chemin vers le dossier qui contient les deux sous-dossiers : 'good' et 'defect'\n",
        "# DATA_DIR = \"screw_dataset\"  # À adapter\n",
        "\n",
        "# BATCH_SIZE = 32\n",
        "# IMG_SIZE = (224, 224)\n",
        "\n",
        "# # Charger toutes les images d'un seul tenant\n",
        "# dataset = image_dataset_from_directory(\n",
        "#     DATA_DIR,\n",
        "#     labels='inferred',\n",
        "#     label_mode='categorical',  # Pour un problème multi-classes, ici on suppose 2 classes (good, defect)\n",
        "#     batch_size=BATCH_SIZE,\n",
        "#     image_size=IMG_SIZE,\n",
        "#     shuffle=True  # Mélange les données\n",
        "# )\n",
        "\n",
        "# # Afficher les classes détectées\n",
        "# class_names = dataset.class_names\n",
        "# print(\"Classes détectées :\", class_names)\n",
        "\n",
        "# # Optionnel : Normalisation et mise en cache\n",
        "# AUTOTUNE = tf.data.AUTOTUNE\n",
        "# def preprocess(image, label):\n",
        "#     image = tf.cast(image, tf.float32) / 255.0  # Normalisation simple\n",
        "#     return image, label\n",
        "\n",
        "# dataset = dataset.map(preprocess).cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "f2a3c4ac",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chargement des images...\n",
            "Found 1152 files belonging to 2 classes.\n",
            "Nombre total d'images: 1152\n",
            "Images 'bad' (label 0): 285\n",
            "Images 'good' (label 1): 867\n",
            "\n",
            "Premiers échantillons après mélange:\n",
            "| N° | Nom de l'image                | Dossier d'origine | Label |\n",
            "|----|--------------------------------|-------------------|-------|\n",
            "|  1 | 020_png.rf.bc1d8a583bfdb217fac2f64731e9771e.jpg | bad             | 0     |\n",
            "|  2 | 196_png.rf.7fe8531648ca4aada3540a77f0ed51f6.jpg | good            | 1     |\n",
            "|  3 | 009_png.rf.4539849089ddf72abf868f1b866a0d09.jpg | good            | 1     |\n",
            "|  4 | 006_png.rf.c13a364cc262b36d021c69ab2a8533dc.jpg | bad             | 0     |\n",
            "|  5 | 010_png.rf.1b22cf6babd655ecd7b71eff26a6310b.jpg | good            | 1     |\n",
            "|  6 | 010_png.rf.49e214452922e22b40fe37eae05704b0.jpg | bad             | 0     |\n",
            "|  7 | 032_png.rf.f74158859e091821a14a89d777c86dfa.jpg | good            | 1     |\n",
            "|  8 | 210_png.rf.2476a4242693cc1c0b22a415c208ff82.jpg | good            | 1     |\n",
            "|  9 | 307_png.rf.2b348fa19f1025ec590df6a0fecba82e.jpg | good            | 1     |\n",
            "| 10 | 090_png.rf.7d126610d0db8d47ffec2a9dc9043bae.jpg | good            | 1     |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/c4/gwh8dn4x50x2lbs830bg6dkc0000gn/T/ipykernel_25689/148269067.py:69: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  label = int(y_shuffled[i])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Ensemble d'entraînement: 806 images\n",
            "  - Bad (0): 199 (24.7%)\n",
            "  - Good (1): 607 (75.3%)\n",
            "\n",
            "Ensemble de validation: 173 images\n",
            "  - Bad (0): 43 (24.9%)\n",
            "  - Good (1): 130 (75.1%)\n",
            "\n",
            "Ensemble de test: 173 images\n",
            "  - Bad (0): 43 (24.9%)\n",
            "  - Good (1): 130 (75.1%)\n",
            "\n",
            "Les datasets sont prêts à être utilisés pour l'entraînement!\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "# Chemin vers le dossier contenant 'good' et 'bad'\n",
        "DATA_DIR = \"screw_dataset\"\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "# Obtenir la liste des noms de fichiers et leurs dossiers d'origine\n",
        "file_paths = []\n",
        "folders = []\n",
        "\n",
        "for class_name in ['bad', 'good']:\n",
        "    class_dir = os.path.join(DATA_DIR, class_name)\n",
        "    for img_name in os.listdir(class_dir):\n",
        "        if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            file_paths.append(os.path.join(class_dir, img_name))\n",
        "            folders.append(class_name)\n",
        "\n",
        "# Chargement des images\n",
        "print(\"Chargement des images...\")\n",
        "dataset = image_dataset_from_directory(\n",
        "    DATA_DIR,\n",
        "    labels='inferred',\n",
        "    label_mode='binary',  # Classification binaire\n",
        "    batch_size=BATCH_SIZE,\n",
        "    image_size=IMG_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Extraction des images et labels\n",
        "all_images = []\n",
        "all_labels = []\n",
        "for images, labels in dataset:\n",
        "    all_images.append(images.numpy())\n",
        "    all_labels.append(labels.numpy())\n",
        "\n",
        "X = np.concatenate(all_images, axis=0) / 255.0  # Normalisation \n",
        "y = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "# Affichage des statistiques de base\n",
        "print(f\"Nombre total d'images: {X.shape[0]}\")\n",
        "print(f\"Images 'bad' (label 0): {np.sum(y == 0)}\")\n",
        "print(f\"Images 'good' (label 1): {np.sum(y == 1)}\")\n",
        "\n",
        "# Mélange des données\n",
        "indices = np.arange(X.shape[0])\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(indices)\n",
        "X_shuffled = X[indices]\n",
        "y_shuffled = y[indices]\n",
        "\n",
        "# On mélange aussi les chemins de fichiers de la même façon\n",
        "file_paths = np.array(file_paths)\n",
        "folders = np.array(folders)\n",
        "file_paths_shuffled = file_paths[indices]\n",
        "folders_shuffled = folders[indices]\n",
        "\n",
        "# Affichage des 10 premiers échantillons après mélange avec nom de fichier et dossier\n",
        "print(\"\\nPremiers échantillons après mélange:\")\n",
        "print(\"| N° | Nom de l'image                | Dossier d'origine | Label |\")\n",
        "print(\"|----|--------------------------------|-------------------|-------|\")\n",
        "for i in range(10):\n",
        "    img_name = os.path.basename(file_paths_shuffled[i])\n",
        "    folder = folders_shuffled[i]\n",
        "    label = int(y_shuffled[i])\n",
        "    print(f\"| {i+1:2d} | {img_name:30s} | {folder:15s} | {label}     |\")\n",
        "\n",
        "# Division train/validation/test (70/15/15)\n",
        "X_train, X_temp, y_train, y_temp, paths_train, paths_temp, folders_train, folders_temp = train_test_split(\n",
        "    X_shuffled, y_shuffled, file_paths_shuffled, folders_shuffled, train_size=0.7, stratify=y_shuffled, random_state=42\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test, paths_val, paths_test, folders_val, folders_test = train_test_split(\n",
        "    X_temp, y_temp, paths_temp, folders_temp, train_size=0.5, stratify=y_temp, random_state=42\n",
        ")\n",
        "\n",
        "# Statistiques des ensembles\n",
        "print(f\"\\nEnsemble d'entraînement: {X_train.shape[0]} images\")\n",
        "print(f\"  - Bad (0): {np.sum(y_train == 0)} ({np.mean(y_train == 0)*100:.1f}%)\")\n",
        "print(f\"  - Good (1): {np.sum(y_train == 1)} ({np.mean(y_train == 1)*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\nEnsemble de validation: {X_val.shape[0]} images\")\n",
        "print(f\"  - Bad (0): {np.sum(y_val == 0)} ({np.mean(y_val == 0)*100:.1f}%)\")\n",
        "print(f\"  - Good (1): {np.sum(y_val == 1)} ({np.mean(y_val == 1)*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\nEnsemble de test: {X_test.shape[0]} images\")\n",
        "print(f\"  - Bad (0): {np.sum(y_test == 0)} ({np.mean(y_test == 0)*100:.1f}%)\")\n",
        "print(f\"  - Good (1): {np.sum(y_test == 1)} ({np.mean(y_test == 1)*100:.1f}%)\")\n",
        "\n",
        "# Création des datasets TensorFlow\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(BATCH_SIZE)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(BATCH_SIZE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(BATCH_SIZE)\n",
        "\n",
        "print(\"\\nLes datasets sont prêts à être utilisés pour l'entraînement!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2NRj6R2GlH6Y",
      "metadata": {
        "id": "2NRj6R2GlH6Y"
      },
      "source": [
        "## 2. Définition d'un modèle simple\n",
        "On définit un modèle CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "0Em3Ej3PlH6Y",
      "metadata": {
        "id": "0Em3Ej3PlH6Y"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/emmacoco/Library/Python/3.9/lib/python/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93312</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,972,032</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m448\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m4,640\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93312\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │     \u001b[38;5;34m5,972,032\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m130\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,977,250</span> (22.80 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,977,250\u001b[0m (22.80 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,977,250</span> (22.80 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,977,250\u001b[0m (22.80 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "num_classes = len(class_names)\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(16, (3, 3), activation='relu', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='mse',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PnYnBDv0lH6Z",
      "metadata": {
        "id": "PnYnBDv0lH6Z"
      },
      "source": [
        "## 3. Entraînement du modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "V4q_eeIZlH6Z",
      "metadata": {
        "id": "V4q_eeIZlH6Z"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 1000  # Nombre d'époques d'entraînement\n",
        "\n",
        "history = model.fit(\n",
        "    dataset,                 # Entraînement ET test sur le même dataset\n",
        "    epochs=EPOCHS,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IquuiFNIlH6a",
      "metadata": {
        "id": "IquuiFNIlH6a"
      },
      "source": [
        "## 4. Évaluation sur le même dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EFp7dBImlH6a",
      "metadata": {
        "id": "EFp7dBImlH6a"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(dataset, verbose=0)\n",
        "print(f\"Loss sur le dataset complet : {loss:.4f}\")\n",
        "print(f\"Accuracy sur le dataset complet : {accuracy:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "name": "bad_training"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
